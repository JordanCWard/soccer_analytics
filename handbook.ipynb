{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqFb2ezNvikD"
   },
   "source": [
    "# Soccer Analytics Handbook Code Samples\n",
    "---\n",
    "\n",
    "Source: [Soccer Analytics Handbook](https://github.com/devinpleuler/analytics-handbook)\n",
    "\n",
    "This version does not require any installation of my own libraries, instead leaning on various *more professional* libraries such as [`statsbombpy`](https://github.com/statsbomb/statsbombpy), [`mplsoccer`](https://github.com/andrewRowlinson/mplsoccer), and [`kloppy`](https://github.com/PySport/kloppy) to accomplish a lot of the plumbing. It can run easily in Google Colab, but can also be cloned to a local enviornment.\n",
    "\n",
    "As with the original code samples, my hope is that this will be a living and breathing document that evolves over time. Pull requests on GitHub are very welcome, and I encourage any proposed changes that you believe better represents best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwzDsNVfvWyS",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup\n",
    "---\n",
    "Run this code block to install `statsbombpy`, `mplsoccer`, and `kloppy`. And import the primary data science packages (e.g. `numpy`, `pandas`, etc.) that most of the code samples require. It also does a few other things like creates some custom colormaps and does some visual configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ynar_bITv0rW"
   },
   "source": [
    "### Packages to Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1ChGn6EvtX1",
    "outputId": "1efb85e5-1841-4e47-ae35-c7c1434efcbb"
   },
   "outputs": [],
   "source": [
    "!pip install statsbombpy==1.12 --quiet\n",
    "!pip install mplsoccer==1.2.4 --quiet\n",
    "!pip install kloppy==3.14.0 --quiet\n",
    "!pip install tqdm==4.66.4 --quiet\n",
    "!pip install scikit-learn==1.5.0 --quiet\n",
    "!pip install xgboost==2.0.3 --quiet\n",
    "!pip install bezier===2023.7.28 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dewih6MFS-A9"
   },
   "source": [
    "### Visual Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yvLGiE6nS5X8"
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "figsize = (9, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLEViw6Xv6zb"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PDBK058Qv3-s"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsbombpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sb\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmplsoccer\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkloppy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrica\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsbombpy\\sb.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsbombpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api_client, public\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsbombpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_CREDS, MAX_CONCURRENCY\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     ArrowDtype,\n\u001b[0;32m     65\u001b[0m     Int8Dtype,\n\u001b[0;32m     66\u001b[0m     Int16Dtype,\n\u001b[0;32m     67\u001b[0m     Int32Dtype,\n\u001b[0;32m     68\u001b[0m     Int64Dtype,\n\u001b[0;32m     69\u001b[0m     UInt8Dtype,\n\u001b[0;32m     70\u001b[0m     UInt16Dtype,\n\u001b[0;32m     71\u001b[0m     UInt32Dtype,\n\u001b[0;32m     72\u001b[0m     UInt64Dtype,\n\u001b[0;32m     73\u001b[0m     Float32Dtype,\n\u001b[0;32m     74\u001b[0m     Float64Dtype,\n\u001b[0;32m     75\u001b[0m     CategoricalDtype,\n\u001b[0;32m     76\u001b[0m     PeriodDtype,\n\u001b[0;32m     77\u001b[0m     IntervalDtype,\n\u001b[0;32m     78\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     79\u001b[0m     StringDtype,\n\u001b[0;32m     80\u001b[0m     BooleanDtype,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     NA,\n\u001b[0;32m     83\u001b[0m     isna,\n\u001b[0;32m     84\u001b[0m     isnull,\n\u001b[0;32m     85\u001b[0m     notna,\n\u001b[0;32m     86\u001b[0m     notnull,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     Index,\n\u001b[0;32m     89\u001b[0m     CategoricalIndex,\n\u001b[0;32m     90\u001b[0m     RangeIndex,\n\u001b[0;32m     91\u001b[0m     MultiIndex,\n\u001b[0;32m     92\u001b[0m     IntervalIndex,\n\u001b[0;32m     93\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     94\u001b[0m     DatetimeIndex,\n\u001b[0;32m     95\u001b[0m     PeriodIndex,\n\u001b[0;32m     96\u001b[0m     IndexSlice,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     NaT,\n\u001b[0;32m     99\u001b[0m     Period,\n\u001b[0;32m    100\u001b[0m     period_range,\n\u001b[0;32m    101\u001b[0m     Timedelta,\n\u001b[0;32m    102\u001b[0m     timedelta_range,\n\u001b[0;32m    103\u001b[0m     Timestamp,\n\u001b[0;32m    104\u001b[0m     date_range,\n\u001b[0;32m    105\u001b[0m     bdate_range,\n\u001b[0;32m    106\u001b[0m     Interval,\n\u001b[0;32m    107\u001b[0m     interval_range,\n\u001b[0;32m    108\u001b[0m     DateOffset,\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     to_numeric,\n\u001b[0;32m    111\u001b[0m     to_datetime,\n\u001b[0;32m    112\u001b[0m     to_timedelta,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     Flags,\n\u001b[0;32m    115\u001b[0m     Grouper,\n\u001b[0;32m    116\u001b[0m     factorize,\n\u001b[0;32m    117\u001b[0m     unique,\n\u001b[0;32m    118\u001b[0m     value_counts,\n\u001b[0;32m    119\u001b[0m     NamedAgg,\n\u001b[0;32m    120\u001b[0m     array,\n\u001b[0;32m    121\u001b[0m     Categorical,\n\u001b[0;32m    122\u001b[0m     set_eng_float_format,\n\u001b[0;32m    123\u001b[0m     Series,\n\u001b[0;32m    124\u001b[0m     DataFrame,\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\api.py:23\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     isna,\n\u001b[0;32m     18\u001b[0m     isnull,\n\u001b[0;32m     19\u001b[0m     notna,\n\u001b[0;32m     20\u001b[0m     notnull,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     factorize,\n\u001b[0;32m     25\u001b[0m     unique,\n\u001b[0;32m     26\u001b[0m     value_counts,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Categorical\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboolean\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BooleanDtype\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py:36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m doc\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     37\u001b[0m     construct_1d_object_array_from_listlike,\n\u001b[0;32m     38\u001b[0m     np_find_common_type,\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     41\u001b[0m     ensure_float64,\n\u001b[0;32m     42\u001b[0m     ensure_object,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     needs_i8_conversion,\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat_compat\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:86\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_list_like\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m     is_valid_na_for_dtype,\n\u001b[0;32m     81\u001b[0m     isna,\n\u001b[0;32m     82\u001b[0m     na_value_for_dtype,\n\u001b[0;32m     83\u001b[0m     notna,\n\u001b[0;32m     84\u001b[0m )\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _arrow_dtype_mapping\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     90\u001b[0m         Sequence,\n\u001b[0;32m     91\u001b[0m         Sized,\n\u001b[0;32m     92\u001b[0m     )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from statsbombpy import sb\n",
    "import mplsoccer as mpl\n",
    "from kloppy import metrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhvkF49CwJhX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNzT9bXWwNRl"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sN2QhN4JqueS"
   },
   "source": [
    "## Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Bs0-t2Hqzuh"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "def bulid_cmap(x, y):\n",
    "    r,g,b = x\n",
    "    r_, g_, b_ = y\n",
    "    N = 256\n",
    "    A = np.ones((N, 4))\n",
    "    A[:, 0] = np.linspace(r, 1, N)\n",
    "    A[:, 1] = np.linspace(g, 1, N)\n",
    "    A[:, 2] = np.linspace(b, 1, N)\n",
    "    cmp = ListedColormap(A)\n",
    "    \n",
    "    B = np.ones((N, 4))\n",
    "    B[:, 0] = np.linspace(r_, 1, N)\n",
    "    B[:, 1] = np.linspace(g_, 1, N)\n",
    "    B[:, 2] = np.linspace(b_, 1, N)\n",
    "    cmp_ = ListedColormap(B)\n",
    "    \n",
    "    newcolors = np.vstack((cmp(np.linspace(0, 1, 128)),\n",
    "                            cmp_(np.linspace(1, 0, 128))))\n",
    "    return ListedColormap(newcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uG6PZ_rjqDQ0"
   },
   "outputs": [],
   "source": [
    "blue, red = (44,123,182), (215,25,28)\n",
    "blue = [x/256 for x in blue]\n",
    "red = [x/256 for x in red]\n",
    "diverging = bulid_cmap(blue, red)\n",
    "diverging_r = bulid_cmap(red, blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tuJ520wwTJp"
   },
   "source": [
    "# Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVVHmJKhwnj4",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9ku6DfUz89b",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kR6jy-bMw3Ih"
   },
   "outputs": [],
   "source": [
    "matches = sb.matches(competition_id=43, season_id=106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmS_FA17w6I_"
   },
   "source": [
    "Call the `matches` method from the `sb` module. The method queries the Statsbomb API to access all of the matches that have a certain competition and season ID. The arguments provided here will access all matches in the 2022 FIFA World Cup.\n",
    "\n",
    "> Notice: you might see a `NoAuthWarning`. This is because you're acessing the StatsBomb open data. If you have a subscription, you can actually pass credentials to these module functions and access your own data. You can quiet these warnings in python if they are annoying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "wqNsLNGOxCpR",
    "outputId": "7ebb208c-c1ff-4b52-b2de-6cde15ab3710"
   },
   "outputs": [],
   "source": [
    "matches.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVTYV4xAxGlz"
   },
   "source": [
    "The matches method returns a Pandas DataFrame object, which you can visualize in various ways including calling the `head` method which takes an argument of the total number of rows that you would like to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLu7_cmGxIV7"
   },
   "outputs": [],
   "source": [
    "final = matches[matches['competition_stage'] == \"Final\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLReDc7hxMli"
   },
   "source": [
    "We filter this DataFrame to return a new DataFrame that only contains rows where the value of the `competition_stage` column is equal to `Final`. \n",
    "\n",
    "The expression `matches['competition_stage'] == \"Final\"` creates a boolean mask with `True` values where the condition is met. This mask is then used to index the original DataFrame resulting in a new DataFrame that contains only the rows where the condition is met.\n",
    "\n",
    "Of course, there is only one World Cup Final match, so we grab the 0th row using the `.iloc` accessor and assign it to a new variable named `final`. At this point, `final` is a Pandas Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsGrwn2exNzt"
   },
   "outputs": [],
   "source": [
    "match_id = final.loc['match_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL11qU08xRK8"
   },
   "source": [
    "We select the `match_id` column from the `final` object usng the `.loc` accessor and assign it to a new variable,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hF6tbdIixP5Q"
   },
   "outputs": [],
   "source": [
    "events = sb.events(match_id = match_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9oToUIHxWBS"
   },
   "source": [
    "Similar to the `sb.matches` method, we use `sb.events` to access all of the events in a particular match, specified by a certain match id. In this example, we are feeding it the `match_id` that corresponds to the FIFA World Cup Final match in 2022 between Argentina and France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqHVI7gd0Bgk"
   },
   "source": [
    "### Passing Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GdMZp36xT7c"
   },
   "outputs": [],
   "source": [
    "passes = events[(events['type'] == \"Pass\") & \n",
    "                (events['player_id'] == 5503)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BneokhK8xbQL"
   },
   "source": [
    "Similar to how we filtered the `matches` DataFrame object for the `Final` match, we filter the events DataFrame object on multiple conditions, including specifying that the event `type` must be `Pass` and the `player_id` must by `5503`, which corresponds to Lionel Messi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5o18glrxd-2"
   },
   "outputs": [],
   "source": [
    "coordinates = passes[['location', 'pass_end_location']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_o0-inqxizF"
   },
   "source": [
    "After filtering the passes DataFrame, we assign the location and pass_end_location columns to a new DataFrame named coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L_2eCxgxkYD"
   },
   "outputs": [],
   "source": [
    "x1, y1 = np.array(coordinates['location'].tolist()).T\n",
    "x2, y2 = np.array(coordinates['pass_end_location'].tolist()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8H50wocVxosW"
   },
   "source": [
    "We extract the location and pass_end_location x/y data from the coordinates DataFrame and convert it to a list using the built-in pandas method tolist.\n",
    "\n",
    "Then, we convert the list into a Numpy array and perform a transpose operation (using `.T`) that switches the rows and columns of the array so that it can easily be unpacked into x and y lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "p-ptADgaxtBa",
    "outputId": "c72c4966-d45f-48f8-a3e5-c33c1f34a2d0"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch()\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "\n",
    "p = pitch.arrows(x1, y1, x2, y2, alpha=0.4, color=blue,\n",
    "                 headaxislength=3, headlength=3, headwidth=4, width=2, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0dIqZ3JxyZS"
   },
   "source": [
    "We create a Pitch object and assign it to the variable pitch.\n",
    "\n",
    "Then, similar to how you would use plt.subplots(...) in Matplotlib, we create a figure and an axis object by invoking the draw method on the Pitch object.\n",
    "\n",
    "Next, we invoke the arrows method, feeding it the pass location lists that we generated above. We also attach various cosmetic attributes pass. We also need to pass it the axis object (ax=ax)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnUH7adI0SjT"
   },
   "source": [
    "### Shot Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKIvw3H90Vtj"
   },
   "outputs": [],
   "source": [
    "shots = events[(events['type'] == \"Shot\") & \n",
    "               (events['team'] == \"Argentina\") &\n",
    "               (events['shot_type'] != \"Penalty\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-gMkYPxLjUm"
   },
   "source": [
    "Similar to how we filtered the event DataFrame for Messi's passes, you can easily filter for Argentinian shots that were not penalties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZ9xhaHL0brB"
   },
   "outputs": [],
   "source": [
    "x, y = np.array(shots['location'].tolist()).T\n",
    "xg = np.array(shots['shot_statsbomb_xg'].tolist())\n",
    "goal = [red if g == \"Goal\" else 'black' for g in shots['shot_outcome'].to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnVeKeYYLv_s"
   },
   "source": [
    "From the filtered dataframe `shots` we grab a couple useful bits of information.\n",
    "\n",
    "First we convert the shot locations to a list and transpose the data so it unpacks into `x` and `y` variables.\n",
    "\n",
    "We grab the Expected Goal values and stick it into the `xg` variable.\n",
    "\n",
    "And finally, we use a list comprehension to iterate through shot outcomes and generate a list that we will use to color our shots. Red if it's a goal, and black if it's not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "9PheD4Y901Pe",
    "outputId": "2d68b683-7fd1-443c-8c19-22e1fa0dffa3"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch()\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "p = pitch.scatter(x, y, s=xg*100, c=goal, alpha=0.8, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5co9xrkMUL_"
   },
   "source": [
    "Similar to how we plotted passes in the previous example, we create a new Pitch and feed the various attributes for population. In particular, pay attention to how we set the size (`s`) attribute to the Expected Goal value (plus a scaling factor of 100 for aesthetics) and the color (`c`) attribute to the outcome of each shot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upW2RvHY0xw-"
   },
   "source": [
    "### Heat Map (Event Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQWDWhuZzLVj"
   },
   "outputs": [],
   "source": [
    "arg_events = events[~pd.isna(events['location']) & \n",
    "                    (events['team'] == \"Argentina\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUZm1NG65iMc"
   },
   "source": [
    "Extract all events that have a location for Argentina and store in seperate pandas DataFrames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YEFHM0VzR6A"
   },
   "outputs": [],
   "source": [
    "x, y = np.array(arg_events['location'].tolist()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zke4C4ue5shS"
   },
   "source": [
    "Grab the location data for each event, convert to a numpy array, and transpose it such that it unpacks seperate `x` and `y` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "uipnTI5VznBP",
    "outputId": "eae23682-c043-4162-c6e4-a150cca82cbe"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch()\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "k = pitch.kdeplot(x, y, cmap='Blues', fill=True, levels=10, alpha=0.8, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtbfY0Uj6C5u"
   },
   "source": [
    "Use the built-in `kdeplot` on the `Pitch` object to construct a Kernel Density Estimation plot on top of the field. The `kdeplot` implementation uses the `seaborn` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuemITSIMUyd"
   },
   "source": [
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jb5yB-QyWa8"
   },
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcYQtpmSokjM"
   },
   "outputs": [],
   "source": [
    "matches_ = matches.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7KSqaDsM0zx"
   },
   "source": [
    "For easy iteration, we convert the `matches` DataFrame from earlier into a dictionary using a built-in pandas method `to_dict`. Specifying the orientation to `records` makes it much easier to work with for our purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDkbAc-R2EPw"
   },
   "outputs": [],
   "source": [
    "n_matches = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDWTpOYmNaGj"
   },
   "source": [
    "For the sake of reasonable processing time, we only load a subset of the matches for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UA3aD8dFooXW",
    "outputId": "137812be-1b5f-48dc-b3a3-bc35ff91498d"
   },
   "outputs": [],
   "source": [
    "all_events = []\n",
    "for m in tqdm(matches_[0:n_matches]):\n",
    "    events = sb.events(match_id = m['match_id'])\n",
    "    passes = events[(events['type'] == \"Pass\")]\n",
    "    coordinates = passes[['location', 'pass_end_location']]\n",
    "    x1, y1 = np.array(coordinates['location'].tolist()).T\n",
    "    x2, y2 = np.array(coordinates['pass_end_location'].tolist()).T\n",
    "    coords = np.vstack((x1, y1, x2, y2)).T\n",
    "    all_events.extend(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOmAAfpkNkSF"
   },
   "source": [
    "The block of code borrows concepts from the earlier examples to filter and extract relevant information. The only previously unused function at this point in the notebook is `vstack` which, stacks multiple numpy arrays vertically. We then transpose to put all the spatial components in their own column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "tNemuWi7pvQK",
    "outputId": "33a96e02-6086-40dd-8e64-5e8104557e1c"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_events, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaXUjHNTONBt"
   },
   "source": [
    "We stick this all back into a new pandas DataFrame named `df`, which is a commonly used variable name for pandas DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4sTZONjyZ3O"
   },
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AA12ASSGpRl4"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG0f0IbnPljl"
   },
   "source": [
    "`scikit-learn` has a k-means clustering implementation that we will borrow from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coqBrDlyuHTT"
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=50)\n",
    "features = df[['x1', 'y1', 'x2', 'y2']]\n",
    "fit = model.fit(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5r16m_R2P3e7"
   },
   "source": [
    "You can get quite far with simply fitting the model on the four passing coordinates in the DataFrame that we constructed.\n",
    "\n",
    "Here we have specificed `n_clusters=50`, but it can handle a few more, or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "pRiG8SXOtpgh",
    "outputId": "9853155a-3fab-4e21-86d0-8040620041a8"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch()\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "for coords in fit.cluster_centers_:\n",
    "  p = pitch.arrows(*coords, alpha=0.5, color=blue, ax=ax,\n",
    "                   headaxislength=2, headlength=2, headwidth=3, width=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApbNbLyCQFLM"
   },
   "source": [
    "After fitting the `KMeans` model, the `fit` residual has various attributes that we can investigate. The most important are the cluster centers, accessed via `cluster_centers_`.\n",
    "\n",
    "For each cluster center, we draw an arrow on the `pitch` object. Notice how we unpack the `coords` variable with an asterick to ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b-9O-ZE4yh-"
   },
   "source": [
    "### Gaussian Mixture Model\n",
    "\n",
    "GMM's aren't used as much in Soccer Analytics as they should be. They're massively useful in various situations and they're super easy to train. Soccer is filled with many non-linear relationships (e.g. passing density surfaces), and GMM's are a computationally cheap and reasonably robust way to model them. Kernel-based non-parametric methods or neural networks might be better suited when otimizing for accuracy, but they have a quite a bit more overhead. And, you can easily resample from them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mih71u8X6u7g"
   },
   "source": [
    "#### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usUbPpv8426Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6aRbvWsQzMu"
   },
   "source": [
    "`scikit-learn` also has a GMM implementation. Most `scikit-learn` models have similar programming interfaces. Notice how we build and train the model in almost exactly the same fashion.\n",
    "\n",
    "Here we've decided to only use `x2` and `y2` attributes as they won't cluster around areas such as the 6-yard-box from goal kicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OltUnm0X5-w2"
   },
   "outputs": [],
   "source": [
    "n_components = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyDCZmNg5QJD"
   },
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=n_components)\n",
    "features = df[['x2', 'y2']]\n",
    "fit = gmm.fit(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dyseiwhROpz"
   },
   "source": [
    "As suggested prior, this `scikit-learn` model is fit in almost the same exact fashion as the k-means model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "St4016FS60Dq"
   },
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3lBuECURaU9"
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3FygWwoRcQ6"
   },
   "source": [
    "Gaussians are elliptical, so we import `Ellipse` from `matplotlib.patches` for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "vpydrJMN5X-C",
    "outputId": "888699d3-2ebd-44ee-d010-cf9e325f6114"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch()\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "for i in range(gmm.n_components):\n",
    "    mean = gmm.means_[i]\n",
    "    cov = gmm.covariances_[i]\n",
    "    eig_val, eig_vec = np.linalg.eig(cov)\n",
    "    angle = np.arctan2(*eig_vec[:,0][::-1])\n",
    "    e = Ellipse(mean,\n",
    "                2*np.sqrt(eig_val[0]), \n",
    "                2*np.sqrt(eig_val[1]), \n",
    "                angle=np.degrees(angle),\n",
    "                color=blue)\n",
    "    e.set_alpha(0.5)\n",
    "    ax.add_artist(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMejg7fJRn-N"
   },
   "source": [
    "Similar to how we interated over the cluster centers on the k-means model, we iterate over the GMM components and grab their means and covariance matrices stored in the `means_` and `covariance_` object attributes.\n",
    "\n",
    "We find the eigenvalues and eigenvectors of each covariance matric using a numpy linear algebra operation, and find the angle of rotation of the first eigenvector using some trigonometry.\n",
    "\n",
    "These features are required for plotting the Ellipse at the correct length, width, and angle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu8_R9oFSJL3"
   },
   "source": [
    "#### Resampling from GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "up-t-akbSK5s"
   },
   "outputs": [],
   "source": [
    "samples = gmm.sample(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5NKcIxpTARf"
   },
   "source": [
    "One really neat feature of GMM's is that you can generate new data from the fitted model. This function creates `5000` new pairs of x and y coordinates and stores it in the `samples` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "n3PZCH_sSbEP",
    "outputId": "bacbc703-c70b-4353-db9a-d0be20a18503"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch()\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "s = pitch.scatter(*samples[0].T, alpha=0.4, color=blue, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8gNmJnVTYS9"
   },
   "source": [
    "We can easily plot these new `samples` using pretty much the same code we used to populate shot charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K05SpAuh64ja"
   },
   "source": [
    "#### Calculating PDF\n",
    "\n",
    "This is a bit advanced subsection, and frankly I don't understand all of the code myself. ChatGPT did some heavy lifting here.\n",
    "\n",
    "But in summary: you can evaluate a GMM as a Probability Density Function across a grid, and apply a contourplot to overlay on top of a `pitch` object.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9hfJ0HLUqUt"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_fpnIDz5dyy"
   },
   "outputs": [],
   "source": [
    "x_min, x_max = 0, 120\n",
    "y_min, y_max = 0, 80\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 120),\n",
    "                     np.linspace(y_min, y_max, 80))\n",
    "\n",
    "Z = np.zeros((xx.shape[0], xx.shape[1], n_components))\n",
    "for i, (mean,\n",
    "        covariance,\n",
    "        weight) in enumerate(zip(gmm.means_,\n",
    "                                 gmm.covariances_,\n",
    "                                 gmm.weights_)):\n",
    "          \n",
    "    Z[:,:,i] = weight * multivariate_normal.pdf(\n",
    "      np.column_stack([xx.ravel(), yy.ravel()]).reshape(\n",
    "          xx.shape + (2,)), mean=mean, cov=covariance)\n",
    "\n",
    "Z = Z.sum(axis=-1)\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "am7e6CyfVVXh"
   },
   "source": [
    "We iterate across all of the GMM components (and their means, covariances, and weights) and use the `multivariate_normal` function from `scipy.stats` to calculate the pdf at each point in the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "Y8NcVffA52x_",
    "outputId": "f531e5e7-b135-4afa-a500-8288c9177822"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch()\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "plot = ax.contourf(xx, yy, Z, levels=10,\n",
    "                   cmap=\"Blues\", alpha=0.8, antialiased=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6CBupmrWAj6"
   },
   "source": [
    "The `mplsoccer` `Pitch` object does not have built-in contour support, but we can still just apply the contour estimate to the same `matplotlib` axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82qvMWRCfosm",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Pass Difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if0gvZ5A48JY"
   },
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Auzb7dsHirEg",
    "outputId": "622e87e0-0997-426c-dc30-05ab8d38f785"
   },
   "outputs": [],
   "source": [
    "all_events = []\n",
    "\n",
    "for m in tqdm(matches_):\n",
    "    events = sb.events(match_id = m['match_id'])\n",
    "    passes = events[(events['type'] == \"Pass\")]\n",
    "    x1, y1 = np.array(passes['location'].tolist()).T\n",
    "    x2, y2 = np.array(passes['pass_end_location'].tolist()).T\n",
    "    outcome = np.array(\n",
    "        [1 if pd.isna(o) else 0 for o in passes['pass_outcome'].values]).T\n",
    "    evs = np.vstack((x1, y1, x2, y2, outcome)).T\n",
    "    all_events.extend(evs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vsqk055knpfZ"
   },
   "source": [
    "This time, we load the entire FIFA World Cup 2022 data into our environment. When building something like a pass difficulty model, we really need a good amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1YKV_uGkjVp"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_events, columns=['x1', 'y1', 'x2', 'y2', 'outcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnoZZ8XGt9Yj"
   },
   "source": [
    "We load all of our data into a pandas DataFrame `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHgwawaflxZh"
   },
   "outputs": [],
   "source": [
    "X = df[['x1', 'y1', 'x2', 'y2']]\n",
    "y = df['outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxwivGPZuRJT"
   },
   "source": [
    "Seperate our training features from our target variable.\n",
    "\n",
    "As is convention, `X` is used for the features and `y` is used for the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqQ4kNUU5C2k"
   },
   "source": [
    "### Split Training/Test Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFzBgmhklfE4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYX5YxQBuCTc"
   },
   "source": [
    "From `scikit-learn`, we import `train_test_split` to help us seperate our training data from our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_J3SMwT1l6ZN"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgVAGou0ubZs"
   },
   "source": [
    "Split the data into training and test data sets, with the `test_size` representing 20% of the overall sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tx2XJzDG5G0e"
   },
   "source": [
    "### Fit XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDl0Ie_el9TJ"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier(random_state=0)\n",
    "fit = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpa3RdMjukFI"
   },
   "source": [
    "Import `xgboost` and train a vanilla classifier with the segmented training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNjcy0D5maf8"
   },
   "outputs": [],
   "source": [
    "y_probs_train = model.predict_proba(X_train)[:, 1]\n",
    "y_probs_test = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grYeN4uPuzSO"
   },
   "source": [
    "Use the fitted model to make predictions on both the training and test data set for the purposes of validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmilcPxZ5NRg"
   },
   "source": [
    "### Evaluate Model using ROC & AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kd8mU_lmWH5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXKAI58MvC0X"
   },
   "source": [
    "Import some methods for evaluating classification models from `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xq4za63Sl_vE"
   },
   "outputs": [],
   "source": [
    "auc_train = roc_auc_score(y_train, y_probs_train)\n",
    "auc_test = roc_auc_score(y_test, y_probs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZB8bjnCVvOoG"
   },
   "source": [
    "Evaluate the `ROC` and `AUC` for the predictions on both the training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "lszu2VgrmdPB",
    "outputId": "ccf677fb-00db-4b1a-d1b1-7f3089a5c36b"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train, y_probs_train)\n",
    "fpr_, tpr_, thresholds_ = roc_curve(y_test, y_probs_test)\n",
    "\n",
    "plt.plot(fpr, tpr, label='Train - ROC curve (area = {:.3f})'.format(auc_train))\n",
    "plt.plot(fpr_, tpr_, label='Test - ROC curve (area = {:.3f})'.format(auc_test))\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo-saCe6vWhZ"
   },
   "source": [
    "As expected, the model performs slightly better on the data set that it was trained on. But, the model performs quite well on the test data set too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkrwcZAh5Td4"
   },
   "source": [
    "### Plot Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4Rgat_2oZIk"
   },
   "outputs": [],
   "source": [
    "y_probs = model.predict_proba(df[['x1', 'y1', 'x2', 'y2']])[:, 1]\n",
    "df['difficulty'] = y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a8DZ-QqvjCY"
   },
   "source": [
    "This estimates the difficulty of every pass in the DataFrame and assigns it to a new column named `difficulty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqU-otNyv4sE"
   },
   "outputs": [],
   "source": [
    "from matplotlib import colormaps as cm\n",
    "cmap = cm['coolwarm_r']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl7RWAx0wK1f"
   },
   "source": [
    "This imports a colormap named `coolwarm` (actually a reverse one named `coolwarm_r`) so we can map numbers to colors easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfsF_Q4rpHvE"
   },
   "outputs": [],
   "source": [
    "coords = df[['x1', 'y1', 'x2', 'y2']].values[100:200].T\n",
    "colors = cmap(df['difficulty'].values[100:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPaQJ_PTw9Fe"
   },
   "source": [
    "This loads `100` pairs of coordinates and pass difficulties mapped to a color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "BzrnyEh9pSCa",
    "outputId": "697b5f8d-3f70-4294-cf1a-76dd22e1592c"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch()\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "p = pitch.arrows(*coords, alpha=0.8, cmap='coolwarm_r', color=colors,\n",
    "                  headaxislength=3, headlength=3, headwidth=4, width=2, ax=ax)\n",
    "plt.colorbar(p, shrink=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llvvWUr8xGhG"
   },
   "source": [
    "We plot the `100` passes, and color them by the difficulty of the pass. Notice that the longer passes tend to be more difficult, and the shorter passes a bit more blue.\n",
    "\n",
    "However, you can also notice some over-fitting here. Pass destinations that intersect the field perimeter have a `0.0` difficulty. The model seems to have learned that passes with this attribute will never complete successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06psowKFT7V0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tracking Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY1Rbv-PVE92"
   },
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yT6VmHd2UUCq"
   },
   "outputs": [],
   "source": [
    "dataset = metrica.load_open_data(\n",
    "    match_id=1,\n",
    "    coordinates=\"metrica\"\n",
    ") # This takes about 60 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqdvOcEG5E56"
   },
   "source": [
    "Kloppy allows for easy access to Metrica's open data, which is the only repository of full tracking data that I'm aware of. This can be done with the `load_open_data` method on the `metrica` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Do1Y0xPqUeci"
   },
   "outputs": [],
   "source": [
    "df = dataset.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSp8sZ4e5pZ3"
   },
   "source": [
    "We can load this data directly into a `pandas` data frame for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "vTui6MTH7MHm",
    "outputId": "d07d175d-2a35-416e-d535-816946617503"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBYbGUAG7Nsp"
   },
   "source": [
    "We can take a quick glance at the shape of the tracking data with a `pd.head` call. Notice that individual `x` and `y` coordinates are stored in different columns for each player.\n",
    "\n",
    "Notice that not all cells are populated (you see a lot of `NaN`s) – this is because it includes players who may not be on the field yet and are possibly not present during a particular frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_ooO5e7Qbwi"
   },
   "outputs": [],
   "source": [
    "frame_rate = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F7EpZxq5v7Q"
   },
   "source": [
    "We store the `frame_rate` in a variable, which is useful for adjusting various things such as per-frame player velocity into more understandable scales (like `m/s`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U61q_lg70XS9"
   },
   "outputs": [],
   "source": [
    "length, width = 105, 68\n",
    "adjust = np.array([length, width])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWLbmnB3593V"
   },
   "source": [
    "The `length` and `width` of the field are stored here, and we create a adjustment factor that is useful for converting from the `metrica` field coordinate system (which goes from `0` to `1` in both the `x` and `y` dimensions) to something a bit more useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP9uSQC_VHaR"
   },
   "source": [
    "### Plot Player Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GULbVZbdhoKT"
   },
   "outputs": [],
   "source": [
    "metrica_attrs = {\"pitch_type\": \"metricasports\",\n",
    "                 \"pitch_length\": length, \n",
    "                 \"pitch_width\": width,\n",
    "                 \"line_color\": \"black\",\n",
    "                 \"linewidth\": 1,\n",
    "                 \"goal_type\": \"circle\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGPYF1Mb6Taw"
   },
   "source": [
    "For the `mplsoccer` `Pitch` object, we've mostly bee using default parameters so far. We've gotten away with this because `statsbomb` is the default `pitch_type` for the module. Here we set a dictionary of keyword arguments that we will unpack into `Pitch` object constructors so it works more natively with `metrica` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3rJH4mt7dvH"
   },
   "outputs": [],
   "source": [
    "hj = list(set([x.split(\"_\")[1] for x in df.columns if \"home\" in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnukOhem7dMX"
   },
   "source": [
    "`hj` is generated via a list comprehension that determines a unique list of numbers in the `df` columns that contains the word `home`. These are the jersey numbers of all of the `home` players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "KfIQjFuGUxBu",
    "outputId": "f5e350f4-db74-4188-e922-4c1685b28d87"
   },
   "outputs": [],
   "source": [
    "start, stop = 4000, 5000 # Frame Range\n",
    "\n",
    "pitch = mpl.Pitch(**metrica_attrs)\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "\n",
    "for j in hj:\n",
    "    path = df[['home_{}_x'.format(j),\n",
    "               'home_{}_y'.format(j)]].values[start:stop]\n",
    "    pitch.plot(*path.T, lw=2, alpha=0.8, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XpEtI7I6viw"
   },
   "source": [
    "This code sample plots the trajectory of all home players from frames `4000` to `5000`.\n",
    "\n",
    "Notice how the metrica attributes are unpacked into the `Pitch` construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2FdLc2l57m_"
   },
   "source": [
    "### High Intensity Runs\n",
    "\n",
    "Counting the number of runs that a player makes during a game is a common ask for data analysts working with tracking data. Below is a very simple and unsophsticated method for couting these instances for a a team during a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvLoPJb_9Ovl"
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for j in hj:\n",
    "    path = df[['home_{}_x'.format(j), 'home_{}_y'.format(j)]].values * adjust\n",
    "    paths.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3DTJQjY9QHu"
   },
   "source": [
    "First, we must extract the `x` and `y` coordinates from the DataFrame for each player, and apply an adjustment factor to convert us from the metrica coordinate system into actual euclidian space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dE79jiz66MUv"
   },
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "speed_threshold = 6\n",
    "sustained_frame_threshold = 10\n",
    "running = False\n",
    "\n",
    "for path in paths:\n",
    "    runs = []\n",
    "    for i, coord in enumerate(path):\n",
    "\n",
    "        displacement = path[i-1]\n",
    "        speed = np.linalg.norm(coord - displacement) * frame_rate\n",
    "        if speed > speed_threshold:\n",
    "            if not running:\n",
    "                running = True\n",
    "                frame_start = i\n",
    "        else:\n",
    "            if running:\n",
    "                running = False\n",
    "                frame_end = i\n",
    "                if frame_end > frame_start + sustained_frame_threshold:\n",
    "                    runs.append((frame_start, frame_end))\n",
    "    all_runs.append(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BK-R7HGb8x7z"
   },
   "source": [
    "This code steps through every single coordinate for a player over time, calculating the positional displacement on a frame-by-frame level. When multiplied by the frame rate, we can get an estimate of a player's instantaneous speed.\n",
    "\n",
    "This is a bit dangerous, as we're only comparing frame-by-frame and imperfections in the data can sometimes lead to unrealistic fluctuations in a player speed. This is particularly dangerous as it can be exacerbated when you're evaluating higher-order derivatives of location such as acceleration.\n",
    "\n",
    "As we iterate frame-by-frame, we check if the speed exceeds our trhreshold (set as `speed_threshold = 6` for a minimum number of frames (set as `sustained_frame_threshold = 10`). We stick the starting and ending frame numbers into a tuple and append it to our `runs` list for accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "7Gup5xdg86Bd",
    "outputId": "6f5fd2e0-8803-4628-b847-a246491ade9c"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch(**metrica_attrs)\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    for (start, stop) in all_runs[i]:\n",
    "        unadjust = np.array(paths[i][start:stop]) * (1 / adjust)\n",
    "        pitch.plot(*unadjust.T, lw=1, c=red, ax=ax, zorder=1)\n",
    "        pitch.scatter(*unadjust[0].T, s=10, color=red, ax=ax)\n",
    "        pitch.scatter(*unadjust[-1].T, s=15, \n",
    "                    facecolor=\"white\", edgecolor=red, zorder=2, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU_4Vk8t-WbE"
   },
   "source": [
    "We can easily plot these runs by slicing our `path` array by the `start` and `stop` frames to create each individual run path.\n",
    "\n",
    "Note: we do have to \"unadjust\" the coordinate data before plotting to get back to the `metrica` coordinate system so it plays nicely with our `mplsoccer` plot.\n",
    "\n",
    "We add a couple dots (filled circle for start, open circle for end) to denote the extremeties of the run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bezier Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting bezier curve to tracking segments can be quite useful for interpretation, serving as a bit of a dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bezier_parameters(X, Y):\n",
    "    T = np.linspace(0, 1, len(X))\n",
    "    M = np.column_stack([(1 - T) ** 2, 2 * T * (1 - T), T ** 2])\n",
    "    points = np.column_stack((X, Y))\n",
    "    return np.linalg.pinv(M) @ points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the parameters of a quadratic (second degree) Bezier curve that fits a set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bezier\n",
    "\n",
    "pitch = mpl.Pitch(**metrica_attrs)\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "\n",
    "beziers = []\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    for (start, stop) in all_runs[i]:\n",
    "        unadjust = np.array(path[start:stop]) * (1 / adjust)\n",
    "\n",
    "        params = np.asarray(get_bezier_parameters(*unadjust.T))\n",
    "        beziers.append(params.T.flatten())\n",
    "\n",
    "        curve = bezier.Curve(params.T, degree=2)\n",
    "        curve.plot(num_pts=100, ax=ax, color=blue)\n",
    "\n",
    "        pitch.scatter(params[0][0], params[0][1], s=10, color=blue, ax=ax)\n",
    "        pitch.scatter(params[2][0], params[2][1], s=10, color=blue, ax=ax, facecolor=\"white\", zorder=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the run paths detected in the previous segment, we fit and plot a Bezier curve for each individual run.\n",
    "\n",
    "And, stores the parameters of each Beizer curve in the `bezier` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans # Actually already imported, but for reference\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(beziers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are only 3 pairs of control points for each Bezier, no matter the length of the run, we can easily perform some clustering to identify some underlying structure in the dataset.\n",
    "\n",
    "Here, we utilize a simple `KMeans` clustering, with `n_clusters=10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_of_interest = 4\n",
    "\n",
    "preds = kmeans.predict(beziers)\n",
    "matches = np.where(preds == cluster_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we arbitrarily select `cluster_of_interest=9` and extract all of the runs in that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch(**metrica_attrs)\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "\n",
    "for m in matches[0]:\n",
    "    params = beziers[m].reshape((2,3))\n",
    "    curve = bezier.Curve(params, degree=2)\n",
    "    curve.plot(num_pts=100, ax=ax, color=\"#ccc\", alpha=0.8)\n",
    "\n",
    "center = kmeans.cluster_centers_[cluster_of_interest].reshape((2,3))\n",
    "curve = bezier.Curve(center, degree=2)\n",
    "curve.plot(num_pts=100, ax=ax, color=blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we cluster all of the runs that belong to the `cluster_of_interest` but also the cluster center, which can be extracted from the `kmeans` object.\n",
    "\n",
    "The limited sample size makes this a bit of a toy example, but this can be quite useful for categorizing run types across an entire season of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Regions and Centroid Normalization\n",
    "\n",
    "Plotting confidence regions around player location is a great alternative to simply plotting their average positions.\n",
    "This provides an understanding of just how variable a player's position might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = df[df['period_id'] == 1] # Grab data from just the first half\n",
    "team = []\n",
    "for j in hj:\n",
    "    track = fh[['home_{}_x'.format(j), 'home_{}_y'.format(j)]].values\n",
    "    team.append(track)\n",
    "tracks = np.array(team)\n",
    "print(tracks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a new `df` that only looks at frames that belong to the first half (`period_id=1`). Otherwise, you would have to perform some additional normalization that adjusts for the flipping of the field at halftime (not too difficult).\n",
    "\n",
    "We parse through the home player jersey numbers, and build individual tracks and create a home team tensor named `tracks`. Notice that the shape of the tracks numpy array is `(10, 71268, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = np.nanmean(tracks, axis=0)\n",
    "adjusted = tracks - centroids + np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get framewise centroids by averaging the team tracks across `axis=0` (i.e. the frames).\n",
    "\n",
    "Next, we can get an adjusted team tensor by subtracking the centroids from the raw tracks. We also have to perform an additional `metrica`-specific adjustment and add `[0.5, 0.5]` to each row to normalize the relative position to the center midfield dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def confidence_region(player_track, confidence_level=0.95):\n",
    "\n",
    "    cov = np.cov(player_track.T)\n",
    "    eig_val, eig_vector = np.linalg.eig(cov)\n",
    "    rads = np.arctan2(eig_vector[1, 0], eig_vector[0, 0])\n",
    "    scale_factor = np.sqrt(chi2.ppf(confidence_level, df=2))\n",
    "\n",
    "    return {\n",
    "        \"xy\": np.mean(player_track, axis=0),\n",
    "        \"width\": np.sqrt(eig_val[0]) * scale_factor,\n",
    "        \"height\": np.sqrt(eig_val[1]) * scale_factor,\n",
    "        \"angle\": np.degrees(rads),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `confidence_region` function takes individual player tracks and returns the attributes that are needed to construct a `matplotlib.patches.Ellipse` object.\n",
    "\n",
    "First, we construct a covariance matrix using `np.cov`, and calculate the eigenvalues and eigenvectors of the covariance matrix using `np.linalg.eig()`.\n",
    "\n",
    "We use those values for various things, including the calculation of the angle (in radians) the distribution is skewed, but also the width and height of the distribution.\n",
    "\n",
    "You can also use the `confidence_level` as a scaling factor to (effectively) adjust the size of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch(**metrica_attrs)\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "for i, t in enumerate(adjusted):\n",
    "\n",
    "    mask = ~np.isnan(t).any(axis=1)\n",
    "    clean_t = t[mask]\n",
    "\n",
    "    if len(clean_t):\n",
    "        ellipse = confidence_region(clean_t, confidence_level=0.75)\n",
    "        e = Ellipse(**ellipse, alpha=0.3)\n",
    "        ax.add_artist(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we plot! Pretty straight forward; feeding the ellipse attributes into a `Ellipse` object and attaching it to the axis.\n",
    "\n",
    "Notice how you can detect what sort of positional variation individual players have, relative to the rest of your team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnM-ePlE_zrJ"
   },
   "source": [
    "### Plot Tracking Frame\n",
    "\n",
    "One of the most common things you will do with tracking data is to plot an individual frame to visualize what is going on at a particular moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCJYOQ69rfbG"
   },
   "outputs": [],
   "source": [
    "n = 500\n",
    "frame = df.iloc[n:n+1]\n",
    "frame_ = df.iloc[n+1:n+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUBcGfw8_Off"
   },
   "source": [
    "For the purpose of this exercise, we are only going to look at frame `500` (and borrow from frame `501` to calculate player displacement and speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sj9wqNiTymJm"
   },
   "outputs": [],
   "source": [
    "bp = frame[['ball_x', 'ball_y']].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycHGX4pg_Zvr"
   },
   "source": [
    "We store the ball position in a variable `bp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOvq30NjnyRi"
   },
   "outputs": [],
   "source": [
    "hj = np.unique([x.split(\"_\")[1] for x in df.columns if \"home\" in x])\n",
    "aj = np.unique([x.split(\"_\")[1] for x in df.columns if \"away\" in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqsP0RIG_ex1"
   },
   "source": [
    "Like in the previous example, we use a list comprehension to grab the jersey numbers for all players on both the `home` and `away` teams and store them in variables `hj` and `aj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJoPeC66_yv8"
   },
   "outputs": [],
   "source": [
    "def team_vectors(f, f_, team, jerseys):\n",
    "    p, v = [], []\n",
    "    for j in jerseys:\n",
    "        pp = f[['{}_{}_x'.format(team, j), '{}_{}_y'.format(team, j)]].values[0]\n",
    "        pp_ = f_[['{}_{}_x'.format(team, j), '{}_{}_y'.format(team, j)]].values[0]\n",
    "        if ~np.isnan(pp[0]):\n",
    "            p.append(pp)\n",
    "            v.append(pp_ - pp)\n",
    "    return np.array(p), np.array(v) * frame_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-miuliiAa2x"
   },
   "source": [
    "This is a helper function for extracting the position and velocity of players belonging to a single team for a pair of sequential frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlEygq2hAFon"
   },
   "outputs": [],
   "source": [
    "hp, hv = team_vectors(frame, frame_, \"home\", hj)\n",
    "ap, av = team_vectors(frame, frame_, \"away\", aj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAkw_VRXBEeK"
   },
   "source": [
    "Using the `team_vectors` helper function, we generate an array that represents team-player coordinates and displacement vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "id": "w2BeAEMLojxM",
    "outputId": "6d8580f6-db67-40bb-c94f-4a55bb99627d"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch(**metrica_attrs)\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "\n",
    "pitch.arrows(*hp.T, *hp.T + hv.T, ax=ax, color='k', zorder=1,\n",
    "             headaxislength=3, headlength=3, headwidth=4, width=1)\n",
    "\n",
    "pitch.arrows(*ap.T, *ap.T + av.T, ax=ax, color='k', zorder=1,\n",
    "             headaxislength=3, headlength=3, headwidth=4, width=1)\n",
    "\n",
    "pitch.scatter(*hp.T, ax=ax, facecolor=red, s=100, edgecolor='k')\n",
    "pitch.scatter(*ap.T, ax=ax, facecolor=blue, s=100, edgecolor='k')\n",
    "pitch.scatter(*bp.T, ax=ax, facecolor='yellow', s=40, edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMe8GNQ0BXC4"
   },
   "source": [
    "No rocket science here, just plotting the player coordinates and displacement vectors on a `metrica` pitch from `mplsoccer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHLaIi4QZmtV"
   },
   "source": [
    "### Time to Intercept\n",
    "\n",
    "Time to Intercept is a foundational component to modern spatial analysis of soccer games, including concepts like Pitch Control from the likes of Will Spearman and Javier Fernandez.\n",
    "\n",
    "In short, it estimates the time it would take for a player to reach a specific location on the soccer field, given an initial starting velocity. This is a computationally expensive problem to solve exactly (and I'm not even sure how to), so it's common to provide a reasonable estimate. Below I have both Laurie Shaw's approximation, and a small modification of my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v82RRrm_b6q0"
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.linspace(0, length, length*2),\n",
    "                     np.linspace(0, width, width*2))\n",
    "\n",
    "indexes = np.stack([xx, yy], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWT0iPfMYf-n"
   },
   "source": [
    "We are going to evaluate `tti` in a grid that has twice as many rows and columns as the soccer field has meters in length and width.\n",
    "\n",
    "This code generates our `numpy` meshgrid using the field dimensions at the cadence specified in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8I0mE3AOsGT"
   },
   "outputs": [],
   "source": [
    "def tti_shaw(origin, destination, velocity,\n",
    "               reaction_time=0.7, max_velocity=5.0):\n",
    "  \n",
    "    r_reaction = origin + velocity * reaction_time\n",
    "    d = destination - r_reaction\n",
    "    return reaction_time + np.linalg.norm(d, axis=-1) / max_velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4u6fChdYAQm"
   },
   "source": [
    "This is the Laurie Shaw `tti` approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ET709QcunFzR"
   },
   "outputs": [],
   "source": [
    "def tti(origin, destination, velocity, reaction_time=0.7, max_velocity=5.0):\n",
    "    u = (origin + velocity) - origin\n",
    "    v = destination - origin\n",
    "    u_mag = np.sqrt(np.sum(u**2, axis=-1))\n",
    "    v_mag = np.sqrt(np.sum(v**2, axis=-1))\n",
    "    dot_product = np.sum(u * v, axis=-1)\n",
    "    angle = np.arccos(dot_product / (u_mag * v_mag))\n",
    "    r_reaction = origin + velocity * reaction_time\n",
    "    d = destination - r_reaction\n",
    "    t = (u_mag * angle/np.pi + \n",
    "         reaction_time + \n",
    "         np.linalg.norm(d, axis=-1) / max_velocity)\n",
    "\n",
    "    return t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQPkw51lYuuX"
   },
   "source": [
    "This is my modification to Laurie's approximation, which incorporates an additional penalty for initial velocities facing away from the target location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQ0wczmIkuh4"
   },
   "outputs": [],
   "source": [
    "def tti_surface(players, velocities, indexes, tti=tti):\n",
    "    pvalues = np.empty((players.shape[0], indexes.shape[0], indexes.shape[1]))\n",
    "    for k in range(players.shape[0]):\n",
    "        pvalues[k, :, :] = tti(players[k], indexes, velocities[k])\n",
    "    values = np.amin(pvalues, axis=0)\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0jMCkSXZAER"
   },
   "source": [
    "This is a lovely piece of code which utilizes `numpy` broadcasting to quickly evaluate `tti` at each cell in the grid, then flattens the many-layered grid into a single layer that represents the minimum value along the vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRik8mpJg8Nb"
   },
   "outputs": [],
   "source": [
    "Z_home = tti_surface(hp * adjust, hv * adjust, indexes)\n",
    "Z_away = tti_surface(ap * adjust, av * adjust, indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfFrrpgHZixO"
   },
   "source": [
    "We create these `tti` surfaces for both the home and away team. Notice the `adjust` variable, which we use to translate the Metrica coordinate system into a representation where we can rely on euclidian space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xeowuJGyrEVA"
   },
   "outputs": [],
   "source": [
    "Z = Z_home - Z_away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvSMdkEvZ87S"
   },
   "source": [
    "We subtract the away surface from the home surface to determine which team can reach each cell of the field representation the fastest, and by what margin (in seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "GPaMU6pfhYHK",
    "outputId": "86b7dc19-97da-4504-9b20-8f305c34d850"
   },
   "outputs": [],
   "source": [
    "pitch = mpl.Pitch(**metrica_attrs)\n",
    "fig, ax = pitch.draw(figsize=figsize)\n",
    "min, max = -1, 1\n",
    "levels = np.linspace(min, max, 11)\n",
    "s = ax.contourf(Z, extent=(0,1,0,1), levels=levels,\n",
    "            cmap=diverging_r, vmin=min, vmax=max, alpha=0.8,\n",
    "            antialiased=True, extend=\"both\")\n",
    "\n",
    "pitch.arrows(*hp.T, *hp.T + hv.T, ax=ax, color='k', zorder=1,\n",
    "             headaxislength=3, headlength=3, headwidth=4, width=1)\n",
    "\n",
    "pitch.arrows(*ap.T, *ap.T + av.T, ax=ax, color='k', zorder=1,\n",
    "             headaxislength=3, headlength=3, headwidth=4, width=1)\n",
    "\n",
    "pitch.scatter(*hp.T, ax=ax, facecolor=red, s=100, edgecolor='k')\n",
    "pitch.scatter(*ap.T, ax=ax, facecolor=blue, s=100, edgecolor='k')\n",
    "pitch.scatter(*bp.T, ax=ax, facecolor='yellow', s=40, edgecolor='k')\n",
    "\n",
    "cbar = plt.colorbar(s, shrink=0.6, ticks=levels)\n",
    "l = cbar.ax.set_yticklabels([\"{:.1f} sec.\".format(t) for t in levels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmOKQXzFaK30"
   },
   "source": [
    "And we plot it as a filled contour, using a diverging color map."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
